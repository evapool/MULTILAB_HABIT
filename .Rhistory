# Dewit
estimate.dewit.day1  = summaryBy(metaBehav ~ cue, data = DEWIT.day1,
FUN = function(x) { c(m = mean(x), s = sd(x), n = length(x)) } )
corr.dewit.day1 = rmcorr(subj,metaBehav[cue == 'Valued'],metaBehav[cue == 'Devalued'],dataset = DEWIT.day1)
estimate.dewit.day3  = summaryBy(metaBehav ~ cue, data = DEWIT.day3,
FUN = function(x) { c(m = mean(x), s = sd(x), n = length(x)) } )
corr.dewit.day3 = rmcorr(subj,metaBehav[cue == 'Valued'],metaBehav[cue == 'Devalued'],dataset = DEWIT.day3)
# Ceceli
estimate.ceceli.day1  = summaryBy(metaBehav ~ cue, data = CECELI.day1,
FUN = function(x) { c(m = mean(x), s = sd(x), n = length(x)) } )
corr.ceceli.day1 = rmcorr(subj,metaBehav[cue == 'Valued'],metaBehav[cue == 'Devalued'],dataset = DEWIT.day1)
estimate.ceceli.day3  = summaryBy(metaBehav ~ cue, data = CECELI.day3,
FUN = function(x) { c(m = mean(x), s = sd(x), n = length(x)) } )
corr.ceceli.day3 = rmcorr(subj,metaBehav[cue == 'Valued'],metaBehav[cue == 'Devalued'],dataset = DEWIT.day3)
# build database for meta-analysis
site           = c ("ICHB: Pasadena1: 1-day "               ,
"ICHB: Pasadena1: 3-day "               ,
"ICHB: Hamburg: 1-day"                  ,
"ICHB: Hamburg: 3-day"                  ,
"ICHB: Pasadena2: 1-day"                ,
"ICHB: Pasadena2: 3-day"                ,
"ICHB: Sydeny: 1-day"                   ,
"ICHB: Sydeny: 3-day"                   ,
"ICHB: Tel-Aviv: 1-day"                 ,
"ICHB: Tel-Aviv: 3-day"                 ,
"De Wit (2018-jep:g): 1-day"             ,
"De Wit (2018-jep:g): 3-day"             ,
"Tricomi (2009-ejn): 1-day"              ,
"Tricomi (2009-ejn): 3-day"              ,
"Ceceli (in prep): 1-day"                ,
"Ceceli (in prep): 3-day")
year           = c ("2017-sept"                                   ,
"2017-sept"                                   ,
"2018-jan"                                    ,
"2018-jan"                                    ,
"2018-may"                                    ,
"2018-may"                                    ,
"2018-may"                                    ,
"2018-may"                                    ,
"2018-june"                                   ,
"2018-june"                                   ,
"2018-jep:g"                                  ,
"2018-jep:g"                                  ,
"2009-ejn"                                    ,
"2009-ejn"                                    ,
"2017-???"                                    ,
"2017-???")
training       = c ("moderate-trainig"                           ,
"extensive-trainig"                          ,
"moderate-trainig"                           ,
"extensive-trainig"                          ,
"moderate-trainig"                           ,
"extensive-trainig"                          ,
"moderate-trainig"                           ,
"extensive-trainig"                          ,
"moderate-trainig"                           ,
"extensive-trainig"                          ,
"moderate-trainig"                           ,
"extensive-trainig"                          ,
"moderate-trainig"                           ,
"extensive-trainig"                          ,
"moderate-trainig"                           ,
"extensive-trainig")
mean_devalued   = c (estimate.caltech.day1$metaBehav.m[1]        ,
estimate.caltech.day3$metaBehav.m[1]          ,
estimate.hamburg.day1$metaBehav.m[1]          ,
estimate.hamburg.day3$metaBehav.m[1]          ,
estimate.caltech2.day1$metaBehav.m[1]         ,
estimate.caltech2.day3$metaBehav.m[1]         ,
estimate.sydney.day1$metaBehav.m[1]           ,
estimate.sydney.day3$metaBehav.m[1]           ,
estimate.telaviv.day1$metaBehav.m[1]          ,
estimate.telaviv.day3$metaBehav.m[1]          ,
estimate.dewit.day1$metaBehav.m[1]            ,
estimate.dewit.day3$metaBehav.m[1]            ,
estimate.tricomi.day1$metaBehav.m[1]          ,
estimate.tricomi.day3$metaBehav.m[1]          ,
estimate.ceceli.day1$metaBehav.m[1]           ,
estimate.ceceli.day3$metaBehav.m[1]) # mean difference prepost for devalued
mean_valued  = c (estimate.caltech.day1$metaBehav.m[2]         ,
estimate.caltech.day3$metaBehav.m[2]         ,
estimate.hamburg.day1$metaBehav.m[2]         ,
estimate.hamburg.day3$metaBehav.m[2]         ,
estimate.caltech2.day1$metaBehav.m[2]        ,
estimate.caltech2.day3$metaBehav.m[2]        ,
estimate.sydney.day1$metaBehav.m[2]          ,
estimate.sydney.day3$metaBehav.m[2]          ,
estimate.telaviv.day1$metaBehav.m[2]         ,
estimate.telaviv.day3$metaBehav.m[2]         ,
estimate.dewit.day1$metaBehav.m[2]            ,
estimate.dewit.day3$metaBehav.m[2]            ,
estimate.tricomi.day1$metaBehav.m[2]          ,
estimate.tricomi.day3$metaBehav.m[2]         ,
estimate.ceceli.day1$metaBehav.m[2]          ,
estimate.ceceli.day3$metaBehav.m[2]) # mean difference prepost for valued) # mean difference prepost for valued
std_devalued  = c (estimate.caltech.day1$metaBehav.s[1]       ,
estimate.caltech.day3$metaBehav.s[1]         ,
estimate.hamburg.day1$metaBehav.s[1]         ,
estimate.hamburg.day3$metaBehav.s[1]         ,
estimate.caltech2.day1$metaBehav.s[1]        ,
estimate.caltech2.day3$metaBehav.s[1]        ,
estimate.sydney.day1$metaBehav.s[1]          ,
estimate.sydney.day3$metaBehav.s[1]          ,
estimate.telaviv.day1$metaBehav.s[1]         ,
estimate.telaviv.day3$metaBehav.s[1]         ,
estimate.dewit.day1$metaBehav.s[1]           ,
estimate.dewit.day3$metaBehav.s[1]           ,
estimate.tricomi.day1$metaBehav.s[1]         ,
estimate.tricomi.day3$metaBehav.s[1]         ,
estimate.ceceli.day1$metaBehav.s[1]         ,
estimate.ceceli.day3$metaBehav.s[1]) # standard deviation  of the difference prepost for valued)
std_valued  = c (estimate.caltech.day1$metaBehav.s[2]          ,
estimate.caltech.day3$metaBehav.s[2]         ,
estimate.hamburg.day1$metaBehav.s[2]         ,
estimate.hamburg.day3$metaBehav.s[2]         ,
estimate.caltech2.day1$metaBehav.s[2]        ,
estimate.caltech2.day3$metaBehav.s[2]        ,
estimate.sydney.day1$metaBehav.s[2]          ,
estimate.sydney.day3$metaBehav.s[2]          ,
estimate.telaviv.day1$metaBehav.s[2]         ,
estimate.telaviv.day3$metaBehav.s[2]         ,
estimate.dewit.day1$metaBehav.s[2]           ,
estimate.dewit.day3$metaBehav.s[2]           ,
estimate.tricomi.day1$metaBehav.s[2]         ,
estimate.tricomi.day3$metaBehav.s[2]         ,
estimate.ceceli.day1$metaBehav.s[2]         ,
estimate.ceceli.day3$metaBehav.s[2]) # standard deviation  of the difference prepost for valued)
n_devalued  = c (estimate.caltech.day1$metaBehav.n[1]           ,
estimate.caltech.day3$metaBehav.n[1]         ,
estimate.hamburg.day1$metaBehav.n[1]         ,
estimate.hamburg.day3$metaBehav.n[1]         ,
estimate.caltech2.day1$metaBehav.n[1]        ,
estimate.caltech2.day3$metaBehav.n[1]        ,
estimate.sydney.day1$metaBehav.n[1]          ,
estimate.sydney.day3$metaBehav.n[1]          ,
estimate.telaviv.day1$metaBehav.n[1]         ,
estimate.telaviv.day3$metaBehav.n[1]         ,
estimate.dewit.day1$metaBehav.n[1]            ,
estimate.dewit.day3$metaBehav.n[1]            ,
estimate.tricomi.day1$metaBehav.n[1]          ,
estimate.tricomi.day3$metaBehav.n[1]          ,
estimate.ceceli.day1$metaBehav.n[1]          ,
estimate.ceceli.day3$metaBehav.n[1]) # standard deviation  of the difference prepost for valued)
n_valued  = c (estimate.caltech.day1$metaBehav.n[2]           ,
estimate.caltech.day3$metaBehav.n[2]         ,
estimate.hamburg.day1$metaBehav.n[2]         ,
estimate.hamburg.day3$metaBehav.n[2]         ,
estimate.caltech2.day1$metaBehav.n[2]        ,
estimate.caltech2.day3$metaBehav.n[2]        ,
estimate.sydney.day1$metaBehav.n[2]          ,
estimate.sydney.day3$metaBehav.n[2]          ,
estimate.telaviv.day1$metaBehav.n[2]         ,
estimate.telaviv.day3$metaBehav.n[2]         ,
estimate.dewit.day1$metaBehav.n[2]           ,
estimate.dewit.day3$metaBehav.n[2]           ,
estimate.tricomi.day1$metaBehav.n[2]         ,
estimate.tricomi.day3$metaBehav.n[2]         ,
estimate.ceceli.day1$metaBehav.n[2]         ,
estimate.ceceli.day3$metaBehav.n[2]) # standard deviation  of the difference prepost for valued)
ri  = c (corr.caltech.day1$r         ,
corr.caltech.day3$r         ,
corr.hamburg.day1$r         ,
corr.hamburg.day3$r         ,
corr.caltech2.day1$r        ,
corr.caltech2.day3$r        ,
corr.sydney.day1$r          ,
corr.sydney.day3$r          ,
corr.telaviv.day1$r         ,
corr.telaviv.day3$r         ,
corr.dewit.day1$r           ,
corr.dewit.day3$r           ,
corr.tricomi.day1$r         ,
corr.tricomi.day3$r         ,
corr.ceceli.day1$r         ,
corr.ceceli.day3$r) # correlation
meta.data
metadata = data.frame( site, year, training, mean_valued, mean_devalued, std_valued, std_devalued, n_valued, n_devalued,ri)
meta.data <- escalc(measure="MC", m1i=mean_valued, m2i=mean_devalued, sd1i=std_valued,sd2i=std_devalued, ni=n_valued,
ri=ri,  data=metadata)
res <- rma.mv(yi, vi, mods = ~ training, random = ~ 1 | site, data=meta.data)
res
res.all <- rma.mv(yi, vi, random = ~ 1 | site, data=meta.data) # for forest plot
### fit random-effects model in the three subgroups
res.day1 <- rma.mv(yi, vi, subset=(training=="moderate-trainig"), data=meta.data)
res.day3 <- rma.mv(yi, vi, subset=(training=="extensive-trainig"), data=meta.data)
res.day1
res.day3 <- rma.mv(yi, vi, subset=(training=="extensive-trainig"), data=meta.data)
res.day3
res.day1
par(mar=c(4,4,1,2)) # decrease margins so the full space is used
par(cex=0.8, font=1)### switch to bold font
forest.plot <- forest(res.all,slab = (meta.data$site),xlim=c(-1.2,2),
ilab = cbind(meta.data$n_valued),
ilab.xpos=c(-0.3), cex=1,ylim=c(1.2,28),
order=order(meta.data$training),rows=c(4:11
,17:24),
xlab="Mean Change", mlab="", psize=1)
### add summary polygons for the three subgroups
addpoly(res.day1, row=15.5, cex=0.75, font=3, mlab="")
addpoly(res.day3, row= 2.5, cex=0.75, font=3, mlab="")
text(-1.2, 15.5, pos=4, cex=0.75, font=3,bquote(paste("RE Model for Moderate training")))
text(-1.2, 2.5, pos=4, cex=0.75, font=3, bquote(paste("RE Model for Extensive training")))
par(mar=c(4,4,1,2)) # decrease margins so the full space is used
par(cex=0.8, font=1)### switch to bold font
forest.plot <- forest(res.all,slab = (meta.data$site),xlim=c(-1.2,2),
ilab = cbind(meta.data$n_valued),
ilab.xpos=c(-0.3), cex=1,ylim=c(1.2,28),
order=order(meta.data$training),rows=c(4:11
,17:24),
xlab="Mean Change", mlab="", psize=1)
dev.off()
par(mar=c(4,4,1,2)) # decrease margins so the full space is used
par(cex=0.8, font=1)### switch to bold font
forest.plot <- forest(res.all,slab = (meta.data$site),xlim=c(-1.2,2),
ilab = cbind(meta.data$n_valued),
ilab.xpos=c(-0.3), cex=1,ylim=c(1.2,28),
order=order(meta.data$training),rows=c(4:11
,17:24),
xlab="Mean Change", mlab="", psize=1)
### add summary polygons for the three subgroups
addpoly(res.day1, row=15.5, cex=0.75, font=3, mlab="")
addpoly(res.day3, row= 2.5, cex=0.75, font=3, mlab="")
text(-1.2, 15.5, pos=4, cex=0.75, font=3,bquote(paste("RE Model for Moderate training")))
text(-1.2, 2.5, pos=4, cex=0.75, font=3, bquote(paste("RE Model for Extensive training")))
par(cex=0.8, font=4)
text(-1.2, c(30,12,25), pos=4, c("Moderate training",
"Extensive training"))
# add column headings to the plot
par(cex=0.8, font=4)### switch to bold font
text(-1, 26.5, "STUDY",  pos=4)
text( 2, 26.5, "MC [95% CI]", pos=2)
par(cex=1, font=3)### switch to bold font
text(-0.3, 26.5, c("N"))
CHANGE.means <- aggregate(CHANGE$normChangeBehav, by = list(CHANGE$ID, CHANGE$group, CHANGE$site), FUN='mean') # extract means
colnames(CHANGE.means) <- c('ID','group','site', 'normChangeBehav')
n_clusters <- stepFlexmix(normChangeBehav ~ group, data = CHANGE.means, control = list(verbose = 0), k = 1:5, nrep = 200)
getModel(n_clusters, "BIC")
94+212
111+46
101+48
157+149
print(table(clusters(mixlm), CHANGE.means$group))
n_clusters <- stepFlexmix(normChangeBehav ~ group, data = CHANGE.means, control = list(verbose = 0), k = 1:5, nrep = 200)
n_clusters
getModel(n_clusters, "BIC")
print(table(clusters(mixlm), CHANGE.means$group))
mixlm <- flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 2)
print(table(clusters(mixlm), CHANGE.means$group))
mixlm <- flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 1)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 1)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 2)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 5)
n_clusters <- stepFlexmix(normChangeBehav ~ group, data = CHANGE.means, control = list(verbose = 0), k = 1:5, nrep = 200)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 2)
n_clusters
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 3)
n_clusters <- stepFlexmix(normChangeBehav ~ group, data = CHANGE.means, control = list(verbose = 0), k = 1:5, nrep = 1000)
getModel(n_clusters, "BIC")
getModel
n_clusters
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 1)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 2)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 5)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 5)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 5)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 5)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 5)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 5)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 4)
n_clusters
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3)
flexmix(normChangeBehav ~ 1, data = CHANGE.means, k = 3,nrep = 1000)
getModel(n_clusters, "BIC")
n_clusters
getModel(n_clusters)
getModel(n_clusters, "ICL")
getModel(n_clusters, which = 1)
getModel(n_clusters, which = 2)
getModel(n_clusters, which = 3)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 3)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 4)
getModel(n_clusters, which = 5)
mixlm <- flexmix(normChangeBehav ~ group, data = CHANGE.means, k = 2)
print(table(clusters(mixlm), CHANGE.means$group))
CHANGE.means$Cluster = factor(clusters(mixlm)) # create a variable based on the clustering
CHANGE.means$group     <- dplyr::recode(CHANGE.means$group, "1-day" = "Moderate training", "3-day" = "Extensive training" )
CHANGE.means$Cluster   <- dplyr::recode(CHANGE.means$Cluster, "2" = "Outcome-insensitive", "1" = "Outcome-sensitive" )
ggplot(CHANGE.means, aes(normChangeBehav, fill = Cluster)) +
geom_histogram(aes(y=..density..),alpha=0.2,binwidth=0.2)+
geom_density(alpha = 0.5)+
xlab('Behavioral adaptation index')+
ylab('Density')+
facet_grid(~group)+
scale_fill_manual(values=c("#F5793A", "#C9C9DB")) +
theme_bw()
# Check if questionnaire data are correlated between them to exclude the possibility to simply enter
# them in the
questionnaires <- aggregate(ANXIETY ~   BIS_total* TICS_CSSS,
data = CHANGE, FUN = mean, na.action = na.pass)
r.questionnaires = cor(questionnaires, use = "pairwise.complete.obs")
# prepare database for the PCA
Q_ACP.means.ID <- aggregate(ANXIETY ~ ID * TICS_SOOV * TICS_PREPE * TICS_WODI * TICS_EXWO * TICS_LACK * TICS_SOTE * TICS_SOIS * TICS_WORY * TICS_WOOV * BIS_motor * BIS_attentional * BIS_nonplanning,
data = CHANGE, FUN = mean, na.action = na.pass) # we do not include the total scales
Q_ACP.means <- Q_ACP.means.ID
Q_ACP.means$ID <- NULL
r.subscale = cor(Q_ACP.means, use = "pairwise.complete.obs")
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
names(Q_ACP.means)[names(Q_ACP.means) == 'V1'] <- 'STAI'
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
library(psych)
questionnaires <- aggregate(ANXIETY ~   BIS_total* TICS_CSSS,
data = CHANGE, FUN = mean, na.action = na.pass)
r.questionnaires = cor(questionnaires, use = "pairwise.complete.obs")
# prepare database for the FA
Q_ACP.means.ID <- aggregate(ANXIETY ~ ID * TICS_SOOV * TICS_PREPE * TICS_WODI * TICS_EXWO * TICS_LACK * TICS_SOTE * TICS_SOIS * TICS_WORY * TICS_WOOV * BIS_motor * BIS_attentional * BIS_nonplanning,
data = CHANGE, FUN = mean, na.action = na.pass) # we do not include the total scales
Q_ACP.means <- Q_ACP.means.ID
Q_ACP.means$ID <- NULL
r.subscale = cor(Q_ACP.means, use = "pairwise.complete.obs")
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
names(Q_ACP.means)[names(Q_ACP.means) == 'V1'] <- 'STAI'
(Q_ACP.means
)
names(Q_ACP.means)[names(Q_ACP.means) == 'V1'] <- 'STAI'
names(Q_ACP.means)[names(Q_ACP.means) == 'V1'] <- 'STAI'
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
describe (Q_ACP.means)
pairs.panels(na.omit(Q_ACP.means))
nFactor  <- fa.parallel(Q_ACP.means, fm = "ml")
library(car)
library(doBy)
library(afex)
library(lme4)
library(lmerTest)
library(ggplot2)
library(BayesFactor)
library(sjstats)
library(jtools)
library(plyr)
library(dplyr)
library(tidyr)
library(metafor)
library(rmcorr)
library(flexmix)
library(psych)
questionnaires <- aggregate(ANXIETY ~   BIS_total* TICS_CSSS,
data = CHANGE, FUN = mean, na.action = na.pass)
r.questionnaires = cor(questionnaires, use = "pairwise.complete.obs")
# prepare database for the FA
Q_ACP.means.ID <- aggregate(ANXIETY ~ ID * TICS_SOOV * TICS_PREPE * TICS_WODI * TICS_EXWO * TICS_LACK * TICS_SOTE * TICS_SOIS * TICS_WORY * TICS_WOOV * BIS_motor * BIS_attentional * BIS_nonplanning,
data = CHANGE, FUN = mean, na.action = na.pass) # we do not include the total scales
Q_ACP.means <- Q_ACP.means.ID
Q_ACP.means$ID <- NULL
# quick look at the covarivance structure
r.subscale = cor(Q_ACP.means, use = "pairwise.complete.obs")
cor.plot(Q_ACP.means,numbers=TRUE,main="correlation matrix")
names(Q_ACP.means)[names(Q_ACP.means) == 'V1'] <- 'STAI'
warnings()
describe (Q_ACP.means)
pairs.panels(na.omit(Q_ACP.means))
warnings()
nFactor  <- fa.parallel(Q_ACP.means, fm = "ml")
warnings()
quest.1.fa <- fa(r = Q_ACP.means, nfactors = 4, rotate = "varimax", fm = "ml")
quest.1.fa
print(quest.1.efa$loadings,cutoff = 0.0)
quest.1.efa <- fa(r = Q_ACP.means, nfactors = 4, rotate = "varimax", fm = "ml")
print(quest.1.efa$loadings,cutoff = 0.0)
fa.diagram(quest.1.pca)
fa.diagram(quest.1.pca)
fa.diagram(quest.1.efa)
s = factor.scores (Q_ACP.means, quest.1.efa)
s
axes <- s$scores
axes
dat <- cbind(Q_ACP.means.ID, axes)
PCA_CHANGE <- join (CHANGE,dat, type = "full")
# run full model
change.inter = lmer(normPressFreq~ group*cue*prepost*(ML1+ML2+ML3+ML4) + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(change.inter)
summary(change.inter)
Confint(change.inter, level = 0.95)
plot(fitted(change.inter),residuals(change.inter))
qqnorm(residuals(change.inter))
hist(residuals(change.inter))
PCA_CHANGE$AFF_pSD <- scale(PCA_CHANGE$ML3, scale = T) + 1 # here I'm going to test at - 1SD (so people that are low in anxiety)
sslop.pSD = lmer(normPressFreq~ group*cue*prepost*AFF_pSD + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
summary(sslop.pSD)
Confint(sslop.pSD, level = 0.95)
PCA_CHANGE$AFF_mSD <- scale(PCA_CHANGE$ML3, scale = T) - 1 # here I'm going to test at + 1SD (so people that are high in anxiety)
sslop.mSD = lmer(normPressFreq ~ group*cue*prepost*AFF_mSD + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(sslop.mSD)
summary(sslop.mSD)
Confint(sslop.mSD, level = 0.95)
summary(sslop.pSD)
summary(change.inter)
Confint(change.inter, level = 0.95)
AFF.means <- aggregate(PCA_CHANGE$normChangeBehav, by = list(PCA_CHANGE$ID, PCA_CHANGE$group, PCA_CHANGE$site, PCA_CHANGE$AFF_pSD, PCA_CHANGE$AFF_mSD, PCA_CHANGE$ML3), FUN='mean', na.rm = T) # extract means
colnames(AFF.means) <- c('ID','group','site', 'AFF_pSD', 'AFF_mSD','AFF', 'normChangeBehav')
acqC1.aov      <- aov_car(normChangeBehav  ~ group*AFF +Error(ID), data = AFF.means, observed = c("AFF"), factorize = F, anova_table = list(es = "pes"))
acqC1.adjmeans <- emmeans(acqC1.aov, specs = c("group"), by = "AFF", at = list(AFF= c(-1, 1)))
library(emmeans)
acqC1.adjmeans <- emmeans(acqC1.aov, specs = c("group"), by = "AFF", at = list(AFF= c(-1, 1)))
acqC1.adjmeans
AFF.means$StressAffect<- ntile(AFF.means$AFF, 2)
AFF.means$StressAffect<- factor(AFF.means$StressAffect)
lowAff.stat    <- aov_car(normChangeBehav  ~ group + site + Error(ID), data = subset(AFF.means, StressAffect == '1'),
observed = c("AFF"), factorize = F, anova_table = list(correction = "GG",es = "pes"))
lowAff.stat
fit <- (aov(normChangeBehav  ~ group + site + Error(ID), data= subset(AFF.means, StressAffect == '1')))
anova_stats(fit$`ID`)
eta_sq(fit, partial = TRUE, ci.lvl = .9)
lowAnx.BF <- anovaBF(normChangeBehav  ~ group + site, data = subset(AFF.means, StressAffect  == '1'),
whichRandom = "ID", iterations = 50000)
lowAnx.BF <- recompute(lowAnx.BF, iterations = 50000)
lowAnx.BF[1]
highAnx.stat    <- aov_car(normChangeBehav  ~ group + site + Error(ID), data = subset(AFF.means, StressAffect == '2'),
observed = c("RC1"), factorize = F, anova_table = list(correction = "GG",es = "pes"))
#
highAnx.stat
fit <- (aov(normChangeBehav  ~ group + site + Error(ID), data= subset(AFF.means, StressAffect == '2')))
anova_stats(fit$`ID`)
eta_sq(fit, partial = TRUE, ci.lvl = .9)
highAnx.BF <- anovaBF(normChangeBehav  ~ group + site, data = subset(AFF.means,  StressAffect == '2'),
whichRandom = "ID", iterations = 50000)
highAnx.BF <- recompute(highAnx.BF, iterations = 50000)
highAnx.BF[1]
AFF.means$StressAffect    <- dplyr::recode(AFF.means$StressAffect, "1" = "Lower Stress Affect", "2" = "Higher Stress Affect" )
AFF.means$group           <- dplyr::recode(AFF.means$group, "1-day" = "Moderate", "3-day" = "Extensive" )
ggplot(AFF.means, aes(x = group, y = normChangeBehav, fill = group, color = group)) +
geom_point(alpha = .5, position = position_jitterdodge(jitter.width = .5, jitter.height = 0)) +
geom_boxplot(alpha=0.3, outlier.alpha = 0) + # do not display outlyers or they will overlap with individual datapoint
ylab('Behavioral adaptation index')+
xlab('Amount of Training')+
facet_grid(~StressAffect)+
scale_fill_manual(values=c("#56B4E9", "#0F2080")) +
scale_color_manual(values=c("#56B4E9", "#092C48")) +
theme_bw()
change.inter = lmer(normPressFreq~ group*cue*prepost*ANXIETY + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(change.inter)
summary(change.inter)
PCA_CHANGE$AFF_pSD <- scale(PCA_CHANGE$ANXIETY, scale = T) + 1 # here I'm going to test at - 1SD (so people that are low in anxiety)
sslop.pSD = lmer(normPressFreq~ group*cue*prepost*AFF_pSD + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(sslop.pSD)
PCA_CHANGE$AFF_mSD <- scale(PCA_CHANGE$ANXIETY, scale = T) - 1 # here I'm going to test at + 1SD (so people that are high in anxiety)
sslop.mSD = lmer(normPressFreq ~ group*cue*prepost*AFF_mSD + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(sslop.mSD)
change.inter = lmer(normPressFreq~ group*cue*prepost*TICS_WORY + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(change.inter)
summary(change.inter)
Confint(change.inter, level = 0.95)
PCA_CHANGE$AFF_pSD <- scale(PCA_CHANGE$TICS_WORY, scale = T) + 1 # here I'm going to test at - 1SD (so people that are low in anxiety)
sslop.pSD = lmer(normPressFreq~ group*cue*prepost*AFF_pSD + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(sslop.pSD)
PCA_CHANGE$AFF_mSD <- scale(PCA_CHANGE$TICS_WORY, scale = T) - 1 # here I'm going to test at + 1SD (so people that are high in anxiety)
sslop.mSD = lmer(normPressFreq ~ group*cue*prepost*AFF_mSD + itemxcondition + site + (1+cue*prepost+itemxcondition|ID), data = PCA_CHANGE, REML=FALSE)
anova(sslop.mSD)
summary(sslop.mSD)
